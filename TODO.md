# TODO - Wallapop Scraper

## 游댮 CR칈TICO - Funcionalidad Esencial

### 1. Verificar y Solucionar Problemas de Ejecuci칩n
- [x] ~~Resolver problema de entorno Python (selenium no encontrado)~~
- [x] ~~Probar ejecuci칩n completa con una b칰squeda de prueba~~
- [x] ~~Verificar que se generen correctamente los CSV y logs~~
- [x] ~~Documentar los pasos exactos de ejecuci칩n en README~~

### 2. Indetectabilidad - Protecci칩n Anti-Bot
- [ ] **Randomizar tiempos de espera**: Actualmente usa `time.sleep()` con valores fijos, muy detectable
  - Implementar delays aleatorios entre 2-5 segundos
  - Variar tiempos entre acciones (click, scroll, navegaci칩n)
- [ ] **User-Agent rotaci칩n**: Agregar rotaci칩n de user agents
- [ ] **Simular comportamiento humano**:
  - Scroll gradual en la p치gina de resultados antes de extraer datos
  - Movimientos de mouse aleatorios
  - Pausas aleatorias al navegar entre productos
- [ ] **Headers adicionales**: Agregar headers realistas (Accept-Language, Accept-Encoding, etc.)
- [ ] **Verificar configuraci칩n de undetected-chromedriver**:
  - Revisar que est칠 usando la versi칩n m치s reciente
  - Configurar opciones adicionales para evasi칩n (disable-blink-features, etc.)

### 3. Gesti칩n Robusta de Errores
- [ ] **Manejo de cookies**: El bloque try-except es muy gen칠rico, puede fallar silenciosamente
  - Agregar reintentos si falla la aceptaci칩n de cookies
  - Verificar que las cookies se hayan aceptado correctamente
- [ ] **B칰squeda**: Si falla `perform_search`, el programa crashea - necesita manejo mejor
- [ ] **Elementos no encontrados**: Mejorar los mensajes de error cuando no se encuentran elementos
- [ ] **Timeout configurables**: Los WebDriverWait usan valores fijos (10, 20), hacerlos configurables
- [ ] **Reintentos**: Implementar sistema de reintentos para p치ginas que no cargan

### 4. Validaci칩n de Datos Extra칤dos
- [ ] **Verificar que se extraen datos**: Algunos items pueden tener estructura diferente
- [ ] **Validar URLs**: Asegurar que las URLs son v치lidas antes de visitarlas
- [ ] **Limpiar datos**: Eliminar espacios extras, caracteres especiales en precios
- [ ] **Detectar productos sin stock/eliminados**: Manejar cuando un producto ya no est치 disponible

## 游리 IMPORTANTE - Estabilidad y Mejoras

### 5. Optimizaci칩n de Esperas y Carga
- [ ] **Esperas inteligentes**: Reemplazar `time.sleep()` fijos por esperas expl칤citas (WebDriverWait)
- [ ] **Verificar carga completa**: Asegurar que la p치gina de resultados carg칩 todos los items
- [ ] **Scroll para cargar m치s items**: Wallapop carga items din치micamente, implementar scroll autom치tico
- [ ] **Detecci칩n de fin de resultados**: Saber cu치ndo ya no hay m치s productos que cargar

### 6. Configuraci칩n Externalizada
- [ ] **Crear config.py o config.json**:
  - Timeouts (min/max delays, wait times)
  - Selectores CSS (f치cil actualizaci칩n si Wallapop cambia el DOM)
  - Opciones de headless/visible
  - N칰mero m치ximo de items a scrapear
  - URL base de Wallapop
- [ ] **Variables de entorno**: Para configuraciones sensibles

### 7. Mejoras en Logging
- [ ] **Niveles de log apropiados**: Usar DEBUG para detalles t칠cnicos, INFO para progreso
- [ ] **Logs m치s informativos**: Agregar contexto (timestamp, query, n칰mero de items)
- [ ] **Log de sesi칩n completa**: Resumen al final (items extra칤dos, errores encontrados, tiempo total)
- [ ] **Consola + archivo**: Mostrar progreso en consola adem치s del archivo log

### 8. Estructura de C칩digo
- [ ] **Separar responsabilidades**: Crear m칩dulos separados
  - `scraper.py`: L칩gica de scraping
  - `parser.py`: Extracci칩n y limpieza de datos
  - `config.py`: Configuraci칩n
  - `utils.py`: Funciones auxiliares (delays, logging, etc.)
- [ ] **Clases**: Convertir a OOP para mejor mantenibilidad
  - Clase `WallapopScraper` con m칠todos bien definidos

### 9. Casos Edge y Validaciones
- [ ] **Sin resultados**: Manejar b칰squedas que no retornan productos
- [ ] **Caracteres especiales**: Sanitizar query antes de usar en nombres de archivos
- [ ] **L칤mite de p치ginas**: Evitar loops infinitos si hay muchos resultados
- [ ] **Conexi칩n perdida**: Detectar y recuperarse de p칠rdida de conexi칩n
- [ ] **Captcha detection**: Detectar si aparece un captcha y pausar/notificar

### 10. Datos Adicionales a Extraer
- [ ] **Im치genes**: URLs de las im치genes del producto
- [ ] **Fecha de publicaci칩n**: Cu치ndo se public칩 el anuncio
- [ ] **Estado del producto**: Nuevo, como nuevo, buen estado, etc.
- [ ] **Vendedor**: Nombre/ID del vendedor (si est치 disponible)
- [ ] **Categor칤a**: Categor칤a del producto
- [ ] **N칰mero de favoritos/vistas**: Si est치 disponible p칰blicamente

## 游릭 FUTURO - Funcionalidades Avanzadas

### 11. Base de Datos (Pr칩xima fase)
- [ ] **Dise침ar esquema**: Tablas para productos, b칰squedas, hist칩rico de precios
- [ ] **SQLite o PostgreSQL**: Decidir motor de base de datos
- [ ] **ORM**: Considerar usar SQLAlchemy para facilitar el manejo
- [ ] **Migraci칩n de datos**: Script para importar CSVs existentes

### 12. Seguimiento de Precios (Requiere BBDD)
- [ ] **Tabla de hist칩rico**: Registrar cambios de precio con timestamp
- [ ] **Comparaci칩n**: Detectar bajadas/subidas de precio
- [ ] **Alertas**: Notificar cuando un producto baja de precio

### 13. Sistema de Notificaciones (Requiere BBDD)
- [ ] **Email**: Enviar resumen de nuevos productos por email
- [ ] **Telegram/Discord**: Bot para notificaciones en tiempo real
- [ ] **Alertas de precio**: Notificar cuando precio baje del umbral deseado

### 14. Filtros Avanzados
- [ ] **Rango de precios**: Filtrar por precio m칤nimo/m치ximo
- [ ] **Ubicaci칩n**: Filtrar por ciudad o distancia
- [ ] **Estado**: Filtrar por estado del producto
- [ ] **Fecha**: Solo productos publicados en las 칰ltimas X horas/d칤as
- [ ] **Palabras clave**: Incluir/excluir productos con ciertas palabras

### 15. Paginaci칩n y Volumen
- [ ] **Scraping de m칰ltiples p치ginas**: Navegar por todas las p치ginas de resultados
- [ ] **L칤mite configurable**: M치ximo de items/p치ginas a scrapear por b칰squeda
- [ ] **Progreso visual**: Barra de progreso para scraping largo

### 16. M칰ltiples B칰squedas
- [ ] **Archivo de b칰squedas**: Leer m칰ltiples queries desde un archivo
- [ ] **B칰squeda programada**: Ejecutar b칰squedas autom치ticamente cada X tiempo
- [ ] **Modo batch**: Procesar m칰ltiples b칰squedas en una sola ejecuci칩n

### 17. Interfaz de Usuario
- [ ] **CLI mejorada**: Argumentos de l칤nea de comandos (argparse)
  - `python main.py --query "MacBook" --max-items 50 --headless`
- [ ] **GUI**: Interfaz gr치fica simple (Tkinter/PyQt) para usuarios no t칠cnicos
- [ ] **Dashboard web**: Flask/FastAPI para visualizar datos y controlar scraping

### 18. Exportaci칩n de Datos
- [ ] **JSON**: Exportar resultados en formato JSON
- [ ] **Excel**: Generar archivos .xlsx con formato
- [ ] **API REST**: Servir datos a trav칠s de API

### 19. Testing y Calidad
- [ ] **Tests unitarios**: Probar funciones individuales
- [ ] **Tests de integraci칩n**: Probar flujo completo (con mock de Wallapop)
- [ ] **Linting**: Configurar flake8/black para calidad de c칩digo
- [ ] **Type hints**: Agregar anotaciones de tipos

### 20. Optimizaci칩n de Rendimiento
- [ ] **Scraping paralelo**: M칰ltiples b칰squedas simult치neas
- [ ] **Cache**: Cachear resultados para evitar scraping repetido
- [ ] **Headless por defecto**: M치s r치pido en producci칩n

## 游닇 Notas Importantes

### Prioridad de Implementaci칩n (Orden Recomendado)
1. **Semana 1**: Cr칤tico #1-4 (Hacer que funcione de forma confiable)
2. **Semana 2**: Importante #5-7 (Estabilidad e indetectabilidad mejorada)
3. **Semana 3**: Importante #8-10 (C칩digo limpio y casos edge)
4. **Mes 2**: Futuro #11-13 (Base de datos y notificaciones)
5. **Mes 3+**: Futuro #14-20 (Features avanzadas)

### Consideraciones de Indetectabilidad
- **Nunca** hacer requests demasiado r치pido (m칤nimo 2-3 segundos entre acciones)
- **Siempre** usar delays aleatorios, no valores fijos
- **Monitorear** si Wallapop actualiza sus medidas anti-bot
- **Respetar** robots.txt y t칠rminos de servicio

### Mantenimiento
- **Actualizar selectores CSS**: Wallapop puede cambiar su HTML en cualquier momento
- **Revisar undetected-chromedriver**: Mantener actualizada la librer칤a
- **Logs**: Revisar logs regularmente para detectar problemas temprano
